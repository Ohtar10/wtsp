{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "artifacts_path = os.path.join(os.path.curdir, 'artifacts/')\n",
    "models_path = os.path.join(artifacts_path, 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   id                                              tweet  \\\n",
       "0  383319220961828867  english boy writes with his notebook positione...   \n",
       "1  383294856249888768  The girls i talk to are like the jobs i get, i...   \n",
       "2  383099313616060416  This I'd what sister are for. @ jolly-hill htt...   \n",
       "3  383357888271360000                                              UOENO   \n",
       "4  383358030852550657  @russmillerdrums thanks for taking time to tal...   \n",
       "\n",
       "      category          other  \n",
       "0  other_topic   writing ways  \n",
       "1  other_topic  relationships  \n",
       "2           na           None  \n",
       "3           na           None  \n",
       "4           na           None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383319220961828867</td>\n      <td>english boy writes with his notebook positione...</td>\n      <td>other_topic</td>\n      <td>writing ways</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>383294856249888768</td>\n      <td>The girls i talk to are like the jobs i get, i...</td>\n      <td>other_topic</td>\n      <td>relationships</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>383099313616060416</td>\n      <td>This I'd what sister are for. @ jolly-hill htt...</td>\n      <td>na</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>383357888271360000</td>\n      <td>UOENO</td>\n      <td>na</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>383358030852550657</td>\n      <td>@russmillerdrums thanks for taking time to tal...</td>\n      <td>na</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"/media/ohtar10/Adder-Storage/datasets/twitter/2013/\"\n",
    "tweets = pd.read_parquet(os.path.join(base_path, 'labeling-completed/tweet-labels.parquet'), engine='pyarrow')\n",
    "tweets.head()"
   ]
  },
  {
   "source": [
    "## Original working data set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  #WeLoveLA Pat Haden meets with NCAA to seek ea...   \n",
       "37  383303035138482176  I had like perfect internet service and then i...   \n",
       "39  383292826219335681  Oh! Got it :) “@_R0YAL_: @cy_dieyi d legoo is ...   \n",
       "41  383322559640379392    We were us is my song right now !❤️❤️❤️❤️❤️❤️❤️   \n",
       "48  383368197853810688  “@justincepriano: I don't understand how peopl...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "39    music  None  \n",
       "41    music  None  \n",
       "48    games  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td>#WeLoveLA Pat Haden meets with NCAA to seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had like perfect internet service and then i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>383292826219335681</td>\n      <td>Oh! Got it :) “@_R0YAL_: @cy_dieyi d legoo is ...</td>\n      <td>music</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>383322559640379392</td>\n      <td>We were us is my song right now !❤️❤️❤️❤️❤️❤️❤️</td>\n      <td>music</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>383368197853810688</td>\n      <td>“@justincepriano: I don't understand how peopl...</td>\n      <td>games</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "filters = [\"home\", \"office\", \"music\", \"health\", \"tech\", \"clothing\", \"games\", \"books\", \"movies\", \"sports\", \"other_product\"]\n",
    "\n",
    "def category_match(string, filters):\n",
    "    categories = string.split(',')\n",
    "    categories = [c.strip() for c in categories]\n",
    "    if set(categories).intersection(filters):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "tweets = tweets.loc[tweets['category'].apply(category_match, args=[filters])]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "from nlpaug.util import Action\n",
    "\n",
    "n_augment = 3"
   ]
  },
  {
   "source": [
    "### Keyboard typo augmentation\n",
    "**Note:** 14 min for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 57.6 s, sys: 7.76 s, total: 1min 5s\nWall time: 14min 43s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # WeLoveLA Pat HaVen meets wOth NCAA to Qeek e...   \n",
       "21  383430944650055680  # seLobeLA Pat Hwden meets with NVAA to seeo e...   \n",
       "21  383430944650055680  # WeLkve,A Pat Haden meeRs wity NCAA to sRek e...   \n",
       "37  383303035138482176  I had like Lertect internet serGide and theJ i...   \n",
       "37  383303035138482176  I had lJke perffvt internet service and then i...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat HaVen meets wOth NCAA to Qeek e...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># seLobeLA Pat Hwden meets with NVAA to seeo e...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLkve,A Pat Haden meeRs wity NCAA to sRek e...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had like Lertect internet serGide and theJ i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had lJke perffvt internet service and then i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "key_aug_path = os.path.join(artifacts_path, 'tweets/tweets_key_aug.parquet')\n",
    "if os.path.exists(key_aug_path):\n",
    "    key_aug = pd.read_parquet(key_aug_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = nac.KeyboardAug()\n",
    "    key_aug = tweets.apply(lambda row: pd.Series({'id': row['id'], \n",
    "                                                        'tweet': aug.augment(row['tweet'], n=n_augment), \n",
    "                                                        'category': row['category'], \n",
    "                                                        'other': row['other']}), \n",
    "                                                        axis=1).explode('tweet')\n",
    "    key_aug.to_parquet(key_aug_path, engine='pyarrow', index=False)\n",
    "    \n",
    "key_aug.head()"
   ]
  },
  {
   "source": [
    "### Embedding substitution\n",
    "**Note:** 5h for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1d 5h 41min 22s, sys: 6min 28s, total: 1d 5h 47min 50s\nWall time: 5h 14s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # WeLoveLA Pat Haden satisfies with AIAW to se...   \n",
       "21  383430944650055680  # WeLoveLA Pat Haden meets whom California_Int...   \n",
       "21  383430944650055680  # WeLoveLA Pat Kaveinga meets bringing nonscho...   \n",
       "37  383303035138482176  I had weird golden internet service and into i...   \n",
       "37  383303035138482176  I gave like perfect internet service and then ...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Haden satisfies with AIAW to se...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Haden meets whom California_Int...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Kaveinga meets bringing nonscho...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had weird golden internet service and into i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I gave like perfect internet service and then ...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "emb_subs_path = os.path.join(artifacts_path, 'tweets/tweets_emb_subs.parquet')\n",
    "if os.path.exists(emb_subs_path):\n",
    "    emb_subs = pd.read_parquet(emb_subs_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = naw.WordEmbsAug(model_type='word2vec', action='substitute', model_path=os.path.join(models_path, 'GoogleNews-vectors-negative300'))\n",
    "    emb_subs = tweets.apply(lambda row: pd.Series({'id': row['id'],\n",
    "                                                'tweet': aug.augment(row['tweet'], n=n_augment),\n",
    "                                                'category': row['category'],\n",
    "                                                'other': row['other']}), axis=1).explode('tweet')\n",
    "    emb_subs.to_parquet(emb_subs_path, engine='pyarrow', index=False)\n",
    "\n",
    "emb_subs.head()                                              "
   ]
  },
  {
   "source": [
    "### Embedding insertion\n",
    "**Note:** 3h 51m for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3h 46min 22s, sys: 7 s, total: 3h 46min 29s\nWall time: 3h 51min 58s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # WeLoveLA Pat Imagine Haden meets with NCAA E...   \n",
       "21  383430944650055680  # WeLoveLA Pat unsubsidized Haden meets Guy wi...   \n",
       "21  383430944650055680  # equaled WeLoveLA Roachton Pat Haden Shares m...   \n",
       "37  383303035138482176  Schiphol I Jan had like perfect internet servi...   \n",
       "37  383303035138482176  I had FAST like perfect internet service Behol...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Imagine Haden meets with NCAA E...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat unsubsidized Haden meets Guy wi...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># equaled WeLoveLA Roachton Pat Haden Shares m...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>Schiphol I Jan had like perfect internet servi...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had FAST like perfect internet service Behol...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "emb_insert_path = os.path.join(artifacts_path, 'tweets/tweets_emb_insert.parquet')\n",
    "if os.path.exists(emb_insert_path):\n",
    "    emb_insert = pd.read_parquet(emb_insert_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = naw.WordEmbsAug(model_type='word2vec', action='insert', model_path=os.path.join(models_path, 'GoogleNews-vectors-negative300'))\n",
    "    emb_insert = tweets.apply(lambda row: pd.Series({'id': row['id'],\n",
    "                                                'tweet': aug.augment(row['tweet'], n=n_augment),\n",
    "                                                'category': row['category'],\n",
    "                                                'other': row['other']}), axis=1).explode('tweet')\n",
    "    emb_insert.to_parquet(emb_insert_path, engine='pyarrow', index=False)\n",
    "\n",
    "emb_insert.head()  "
   ]
  },
  {
   "source": [
    "### Synonim substitution\n",
    "**Note:** 14 min for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2min 5s, sys: 8.79 s, total: 2min 14s\nWall time: 14min 41s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # WeLoveLA Pat Haden meet with NCAA to try eas...   \n",
       "21  383430944650055680  # WeLoveLA Pat Haden meet with NCAA to seek re...   \n",
       "21  383430944650055680  # WeLoveLA Pat Haden meet with NCAA to seek ea...   \n",
       "37  383303035138482176  I make comparable perfect cyberspace service a...   \n",
       "37  383303035138482176  I had like everlasting internet service and th...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Haden meet with NCAA to try eas...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Haden meet with NCAA to seek re...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># WeLoveLA Pat Haden meet with NCAA to seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I make comparable perfect cyberspace service a...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had like everlasting internet service and th...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "synonim_aug_path = os.path.join(artifacts_path, 'tweets/tweets_synonim_aug.parquet')\n",
    "if os.path.exists(synonim_aug_path):\n",
    "    synonim_aug = pd.read_parquet(synonim_aug_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = naw.SynonymAug(aug_src='wordnet')\n",
    "    synonim_aug = tweets.apply(lambda row: pd.Series({'id': row['id'],\n",
    "                                                'tweet': aug.augment(row['tweet'], n=n_augment),\n",
    "                                                'category': row['category'],\n",
    "                                                'other': row['other']}), axis=1).explode('tweet')\n",
    "    synonim_aug.to_parquet(synonim_aug_path, engine='pyarrow', index=False)\n",
    "\n",
    "synonim_aug.head()   "
   ]
  },
  {
   "source": [
    "### Context insertion with BERT\n",
    "**Note:** 1h 47min for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 10h 40min 36s, sys: 2min 42s, total: 10h 43min 18s\nWall time: 1h 47min 20s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # kevin welovela and pat al haden first meets ...   \n",
       "21  383430944650055680  # welovela pat haden regularly meets daily wit...   \n",
       "21  383430944650055680  # welovela group pat john haden meets with nca...   \n",
       "37  383303035138482176  i had like perfect internet service and then.....   \n",
       "37  383303035138482176  and i had like perfect normal internet service...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># kevin welovela and pat al haden first meets ...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># welovela pat haden regularly meets daily wit...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># welovela group pat john haden meets with nca...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>i had like perfect internet service and then.....</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>and i had like perfect normal internet service...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ctx_insert_path = os.path.join(artifacts_path, 'tweets/tweets_ctx_insert_aug.parquet')\n",
    "\n",
    "if os.path.exists(ctx_insert_path):\n",
    "    ctx_insert = pd.read_parquet(ctx_insert_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = naw.ContextualWordEmbsAug(action='insert')\n",
    "    ctx_insert = tweets.apply(lambda row: pd.Series({'id': row['id'], \n",
    "                                                        'tweet': aug.augment(row['tweet'], n=n_augment), \n",
    "                                                        'category': row['category'], \n",
    "                                                        'other': row['other']}), \n",
    "                                                        axis=1).explode('tweet')\n",
    "    ctx_insert.to_parquet(ctx_insert_path, engine='pyarrow', index=False)\n",
    "ctx_insert.head()"
   ]
  },
  {
   "source": [
    "### Context substitution with BERT\n",
    "**Note:** 1h 36m min for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 9h 33min 13s, sys: 2min 34s, total: 9h 35min 48s\nWall time: 1h 36min\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  # 7 pat had meets before ncaa referees seek ea...   \n",
       "21  383430944650055680  # peggy lee boone meets with ncaa that seek en...   \n",
       "21  383430944650055680  # president pat robertson tells his ncaa to po...   \n",
       "37  383303035138482176  i could like perfect internet service and here...   \n",
       "37  383303035138482176  i had pretty perfect telephone service so then...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># 7 pat had meets before ncaa referees seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># peggy lee boone meets with ncaa that seek en...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td># president pat robertson tells his ncaa to po...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>i could like perfect internet service and here...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>i had pretty perfect telephone service so then...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ctx_subs_path = os.path.join(artifacts_path, 'tweets/tweets_ctx_substitute_aug.parquet')\n",
    "\n",
    "if os.path.exists(ctx_subs_path):\n",
    "    ctx_subs = pd.read_parquet(ctx_subs_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = naw.ContextualWordEmbsAug(action='substitute')\n",
    "    ctx_subs = tweets.apply(lambda row: pd.Series({'id': row['id'], \n",
    "                                                        'tweet': aug.augment(row['tweet'], n=n_augment), \n",
    "                                                        'category': row['category'], \n",
    "                                                        'other': row['other']}), \n",
    "                                                        axis=1).explode('tweet')\n",
    "    ctx_subs.to_parquet(ctx_subs_path, engine='pyarrow', index=False)\n",
    "ctx_subs.head()"
   ]
  },
  {
   "source": [
    "### Sentence augmentation with BERT\n",
    "**Note:** 13h for ~8k records with 3 new examples augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3d 5h 27min 16s, sys: 28min 19s, total: 3d 5h 55min 35s\nWall time: 13h 51s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "21  383430944650055680  #WeLoveLA Pat Haden meets with NCAA to seek ea...   \n",
       "21  383430944650055680  #WeLoveLA Pat Haden meets with NCAA to seek ea...   \n",
       "21  383430944650055680  #WeLoveLA Pat Haden meets with NCAA to seek ea...   \n",
       "37  383303035138482176  I had like perfect internet service and then i...   \n",
       "37  383303035138482176  I had like perfect internet service and then i...   \n",
       "\n",
       "   category other  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "21   sports  None  \n",
       "37     tech  None  \n",
       "37     tech  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td>#WeLoveLA Pat Haden meets with NCAA to seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td>#WeLoveLA Pat Haden meets with NCAA to seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>383430944650055680</td>\n      <td>#WeLoveLA Pat Haden meets with NCAA to seek ea...</td>\n      <td>sports</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had like perfect internet service and then i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>383303035138482176</td>\n      <td>I had like perfect internet service and then i...</td>\n      <td>tech</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ctx_sent_aug_path = os.path.join(artifacts_path, 'tweets/tweets_ctx_sent_aug.parquet')\n",
    "\n",
    "if os.path.exists(ctx_sent_aug_path):\n",
    "    ctx_sent_aug = pd.read_parquet(ctx_sent_aug_path, engine='pyarrow')\n",
    "else:\n",
    "    aug = nas.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased')\n",
    "    ctx_sent_aug = tweets.apply(lambda row: pd.Series({'id': row['id'], \n",
    "                                                        'tweet': aug.augment(row['tweet'], n=n_augment), \n",
    "                                                        'category': row['category'], \n",
    "                                                        'other': row['other']}), \n",
    "                                                        axis=1).explode('tweet')\n",
    "    ctx_sent_aug.to_parquet(ctx_sent_aug_path, engine='pyarrow', index=False)\n",
    "ctx_sent_aug.head()"
   ]
  },
  {
   "source": [
    "### Put all togheter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_path = os.path.join(artifacts_path, 'tweets/all_tweets.parquet')\n",
    "\n",
    "if os.path.exists(all_tweets_path):\n",
    "    all_tweets = pd.read_parquet(all_tweets_path, engine='pyarrow')\n",
    "else:\n",
    "    all_tweets = pd.concat([\n",
    "            tweets,\n",
    "            key_aug,\n",
    "            emb_subs,\n",
    "            emb_insert,\n",
    "            synonim_aug,\n",
    "            ctx_insert,\n",
    "            ctx_subs,\n",
    "            ctx_sent_aug\n",
    "        ])\n",
    "    all_tweets.to_parquet(all_tweets_path, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('wtsp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "60f1df135fa14e0a8cd6f1cba451775870a2013e1541c01995e720fc6b462c84"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}